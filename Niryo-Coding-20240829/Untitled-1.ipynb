{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'segment-anything-2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/segment-anything-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"  # Provide the path to the small SAM model checkpoint\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected HSV Color: (77.27839667977283, 57.01277850589777, 64.93042813455658, 0.0)\n",
      "Detected HSV Color: (42.93906588308073, 8.456387256418187, 169.53263223012684, 0.0)\n",
      "Detected HSV Color: (39.94195568400771, 8.56791907514451, 170.743978805395, 0.0)\n",
      "Detected HSV Color: (66.58704008786381, 6.285557386051621, 172.2720117151748, 0.0)\n",
      "Detected HSV Color: (0.0, 0.0, 0.0, 0.0)\n",
      "Detected HSV Color: (0.0, 0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "def detect_color(mask, image):\n",
    "    \"\"\"Detect the average color of the masked region\"\"\"\n",
    "    # Create a mask of the region\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Convert to HSV color space for better color detection\n",
    "    hsv = cv2.cvtColor(masked_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the average color in the masked area\n",
    "    mean_color = cv2.mean(hsv, mask=mask)\n",
    "    return mean_color\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (256, 256))\n",
    "    resized_frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use SAM to predict the mask for the frame\n",
    "    predictor.set_image(resized_frame_rgb)\n",
    "    masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "    # Loop over the masks (choose the highest score mask for simplicity)\n",
    "    best_mask_index = np.argmax(scores)\n",
    "    best_mask = masks[best_mask_index].astype(np.uint8) * 255\n",
    "\n",
    "    # Detect the color of the segmented object\n",
    "    mean_color = detect_color(best_mask, resized_frame)\n",
    "\n",
    "    # Display the results\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Segmented Mask\", best_mask)\n",
    "\n",
    "    # Display color in HSV format\n",
    "    print(f\"Detected HSV Color: {mean_color}\")\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for colored mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"  # Make sure this path is correct\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def apply_colored_mask(image, mask, color):\n",
    "    \"\"\"Apply color to a binary mask and overlay on image.\"\"\"\n",
    "    colored_mask = np.zeros_like(image)  # Create an empty colored mask (same size as image)\n",
    "    colored_mask[mask == 255] = color  # Apply the color where the mask is active\n",
    "    return cv2.addWeighted(image, 1, colored_mask, 0.6, 0)  # Blend original image with the mask\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (256, 256))\n",
    "    resized_frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use SAM to predict the mask for the frame\n",
    "    predictor.set_image(resized_frame_rgb)\n",
    "    masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "    # Loop over the masks (choose the highest score mask for simplicity)\n",
    "    best_mask_index = np.argmax(scores)\n",
    "    best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "    # Generate a random color for the mask\n",
    "    color = np.random.randint(0, 255, size=(3,), dtype=int).tolist()  # Random BGR color\n",
    "\n",
    "    # Apply the colored mask to the frame\n",
    "    colored_frame = apply_colored_mask(resized_frame, best_mask, color)\n",
    "\n",
    "    # Display the results\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Colored Segmentation Mask\", colored_frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colored mask to circular objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"./sam_vit_b.pth\"  # Make sure this path is correct\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detect_circles(image):\n",
    "    \"\"\"Detect circular objects in the frame using HoughCircles\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30, param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        return circles[0, :]  # Return the detected circles\n",
    "    return None\n",
    "\n",
    "def apply_colored_mask(image, mask, color):\n",
    "    \"\"\"Apply color to a binary mask and overlay it on the image.\"\"\"\n",
    "    colored_mask = np.zeros_like(image)  # Create an empty mask the same size as the image\n",
    "    colored_mask[mask == 255] = color  # Apply the color where the mask is active\n",
    "    return cv2.addWeighted(image, 1, colored_mask, 0.6, 0)  # Blend original image with the mask\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (640, 480))\n",
    "    resized_frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect circles in the frame\n",
    "    circles = detect_circles(resized_frame)\n",
    "\n",
    "    if circles is not None:\n",
    "        for circle in circles:\n",
    "            x, y, r = circle\n",
    "            # Create a mask for the detected circle\n",
    "            mask = np.zeros_like(resized_frame[:, :, 0])  # Create a black mask\n",
    "            cv2.circle(mask, (x, y), r, 255, thickness=-1)  # Fill the circle region with white (255)\n",
    "\n",
    "            # Use SAM to predict the mask for the circular region only\n",
    "            predictor.set_image(resized_frame_rgb)\n",
    "            masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "            # Loop over the masks (choose the highest score mask for simplicity)\n",
    "            best_mask_index = np.argmax(scores)\n",
    "            best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "            # Combine circle mask and segmentation mask (apply segmentation only to the circular area)\n",
    "            combined_mask = cv2.bitwise_and(best_mask, mask)\n",
    "\n",
    "            # Generate a random color for the mask\n",
    "            color = np.random.randint(0, 255, size=(3,), dtype=int).tolist()  # Random BGR color\n",
    "\n",
    "            # Apply the colored mask to the frame\n",
    "            colored_frame = apply_colored_mask(resized_frame, combined_mask, color)\n",
    "\n",
    "            # Draw the detected circle (optional for visualization)\n",
    "            cv2.circle(resized_frame, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the results\n",
    "            cv2.imshow(\"Colored Segmentation Mask\", colored_frame)\n",
    "    else:\n",
    "        cv2.imshow(\"Original Frame\", resized_frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code with semantic segmentation\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"./sam_vit_b.pth\"  # Make sure this path is correct\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "def detect_circles(image):\n",
    "    \"\"\"Detect circular objects in the frame using HoughCircles\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30, param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        return circles[0, :]  # Return the detected circles\n",
    "    return None\n",
    "\n",
    "def apply_colored_mask(image, mask, color):\n",
    "    \"\"\"Apply color to a binary mask and overlay it on the image.\"\"\"\n",
    "    colored_mask = np.zeros_like(image)  # Create an empty mask the same size as the image\n",
    "    colored_mask[mask == 255] = color  # Apply the color where the mask is active\n",
    "    return cv2.addWeighted(image, 1, colored_mask, 0.6, 0)  # Blend original image with the mask\n",
    "\n",
    "# Load the input image from a file\n",
    "image_path = \"path_to_your_image.jpg\"  # Replace with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "    exit()\n",
    "\n",
    "# Resize the image for faster processing\n",
    "resized_image = cv2.resize(image, (640, 480))\n",
    "resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect circles in the image\n",
    "circles = detect_circles(resized_image)\n",
    "\n",
    "if circles is not None:\n",
    "    for circle in circles:\n",
    "        x, y, r = circle\n",
    "        # Create a mask for the detected circle\n",
    "        mask = np.zeros_like(resized_image[:, :, 0])  # Create a black mask\n",
    "        cv2.circle(mask, (x, y), r, 255, thickness=-1)  # Fill the circle region with white (255)\n",
    "\n",
    "        # Use SAM to predict the mask for the circular region only\n",
    "        predictor.set_image(resized_image_rgb)\n",
    "        masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "        # Loop over the masks (choose the highest score mask for simplicity)\n",
    "        best_mask_index = np.argmax(scores)\n",
    "        best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "        # Combine circle mask and segmentation mask (apply segmentation only to the circular area)\n",
    "        combined_mask = cv2.bitwise_and(best_mask, mask)\n",
    "\n",
    "        # Generate a random color for the mask\n",
    "        color = np.random.randint(0, 255, size=(3,), dtype=int).tolist()  # Random BGR color\n",
    "\n",
    "        # Apply the colored mask to the image\n",
    "        colored_image = apply_colored_mask(resized_image, combined_mask, color)\n",
    "\n",
    "        # Draw the detected circle (optional for visualization)\n",
    "        cv2.circle(resized_image, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the results\n",
    "        cv2.imshow(\"Colored Segmentation Mask\", colored_image)\n",
    "else:\n",
    "    cv2.imshow(\"Original Image\", resized_image)\n",
    "\n",
    "# Press any key to close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limport cv2\n",
    "import time\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Load the SAM model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"path/to/checkpoint.pth\")\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)  # Change '0' if you have multiple cameras\n",
    "\n",
    "# Capture an image every 3 seconds and perform segmentation\n",
    "while True:\n",
    "    # Capture an image from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image.\")\n",
    "        break\n",
    "\n",
    "    # Set the image for segmentation\n",
    "    predictor.set_image(frame)\n",
    "    \n",
    "    # You can provide manual points for segmentation, or let the model handle it based on other criteria\n",
    "    # Example point (x, y) can be provided based on prior knowledge of chip locations\n",
    "    masks, scores, _ = predictor.predict(point_coords=[[x, y]], point_labels=[1])\n",
    "\n",
    "    # Display the image with segmentation results (optional)\n",
    "    binary_mask = (masks[0] > 0).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw contours on the frame\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "        if 0.7 <= circularity <= 1.2:  # Circularity close to 1 indicates a circle\n",
    "            cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Show the processed image\n",
    "    cv2.imshow('Segmented Image', frame)\n",
    "\n",
    "    # Wait for 3 seconds before capturing the next frame\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
