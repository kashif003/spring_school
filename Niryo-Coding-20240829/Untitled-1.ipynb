{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'segment-anything-2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/segment-anything-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"  # Provide the path to the small SAM model checkpoint\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected HSV Color: (77.27839667977283, 57.01277850589777, 64.93042813455658, 0.0)\n",
      "Detected HSV Color: (42.93906588308073, 8.456387256418187, 169.53263223012684, 0.0)\n",
      "Detected HSV Color: (39.94195568400771, 8.56791907514451, 170.743978805395, 0.0)\n",
      "Detected HSV Color: (66.58704008786381, 6.285557386051621, 172.2720117151748, 0.0)\n",
      "Detected HSV Color: (0.0, 0.0, 0.0, 0.0)\n",
      "Detected HSV Color: (0.0, 0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "def detect_color(mask, image):\n",
    "    \"\"\"Detect the average color of the masked region\"\"\"\n",
    "    # Create a mask of the region\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Convert to HSV color space for better color detection\n",
    "    hsv = cv2.cvtColor(masked_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the average color in the masked area\n",
    "    mean_color = cv2.mean(hsv, mask=mask)\n",
    "    return mean_color\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (256, 256))\n",
    "    resized_frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use SAM to predict the mask for the frame\n",
    "    predictor.set_image(resized_frame_rgb)\n",
    "    masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "    # Loop over the masks (choose the highest score mask for simplicity)\n",
    "    best_mask_index = np.argmax(scores)\n",
    "    best_mask = masks[best_mask_index].astype(np.uint8) * 255\n",
    "\n",
    "    # Detect the color of the segmented object\n",
    "    mean_color = detect_color(best_mask, resized_frame)\n",
    "\n",
    "    # Display the results\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Segmented Mask\", best_mask)\n",
    "\n",
    "    # Display color in HSV format\n",
    "    print(f\"Detected HSV Color: {mean_color}\")\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for colored mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"  # Make sure this path is correct\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def apply_colored_mask(image, mask, color):\n",
    "    \"\"\"Apply color to a binary mask and overlay on image.\"\"\"\n",
    "    colored_mask = np.zeros_like(image)  # Create an empty colored mask (same size as image)\n",
    "    colored_mask[mask == 255] = color  # Apply the color where the mask is active\n",
    "    return cv2.addWeighted(image, 1, colored_mask, 0.6, 0)  # Blend original image with the mask\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (256, 256))\n",
    "    resized_frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use SAM to predict the mask for the frame\n",
    "    predictor.set_image(resized_frame_rgb)\n",
    "    masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "    # Loop over the masks (choose the highest score mask for simplicity)\n",
    "    best_mask_index = np.argmax(scores)\n",
    "    best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "    # Generate a random color for the mask\n",
    "    color = np.random.randint(0, 255, size=(3,), dtype=int).tolist()  # Random BGR color\n",
    "\n",
    "    # Apply the colored mask to the frame\n",
    "    colored_frame = apply_colored_mask(resized_frame, best_mask, color)\n",
    "\n",
    "    # Display the results\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Colored Segmentation Mask\", colored_frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colored mask to circular objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"./sam_vit_b.pth\"  # Make sure this path is correct\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detect_circles(image):\n",
    "    \"\"\"Detect circular objects in the frame using HoughCircles\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30, param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        return circles[0, :]  # Return the detected circles\n",
    "    return None\n",
    "\n",
    "def apply_colored_mask(image, mask, color):\n",
    "    \"\"\"Apply color to a binary mask and overlay it on the image.\"\"\"\n",
    "    colored_mask = np.zeros_like(image)  # Create an empty mask the same size as the image\n",
    "    colored_mask[mask == 255] = color  # Apply the color where the mask is active\n",
    "    return cv2.addWeighted(image, 1, colored_mask, 0.6, 0)  # Blend original image with the mask\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (640, 480))\n",
    "    resized_frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect circles in the frame\n",
    "    circles = detect_circles(resized_frame)\n",
    "\n",
    "    if circles is not None:\n",
    "        for circle in circles:\n",
    "            x, y, r = circle\n",
    "            # Create a mask for the detected circle\n",
    "            mask = np.zeros_like(resized_frame[:, :, 0])  # Create a black mask\n",
    "            cv2.circle(mask, (x, y), r, 255, thickness=-1)  # Fill the circle region with white (255)\n",
    "\n",
    "            # Use SAM to predict the mask for the circular region only\n",
    "            predictor.set_image(resized_frame_rgb)\n",
    "            masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "            # Loop over the masks (choose the highest score mask for simplicity)\n",
    "            best_mask_index = np.argmax(scores)\n",
    "            best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "            # Combine circle mask and segmentation mask (apply segmentation only to the circular area)\n",
    "            combined_mask = cv2.bitwise_and(best_mask, mask)\n",
    "\n",
    "            # Generate a random color for the mask\n",
    "            color = np.random.randint(0, 255, size=(3,), dtype=int).tolist()  # Random BGR color\n",
    "\n",
    "            # Apply the colored mask to the frame\n",
    "            colored_frame = apply_colored_mask(resized_frame, combined_mask, color)\n",
    "\n",
    "            # Draw the detected circle (optional for visualization)\n",
    "            cv2.circle(resized_frame, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the results\n",
    "            cv2.imshow(\"Colored Segmentation Mask\", colored_frame)\n",
    "    else:\n",
    "        cv2.imshow(\"Original Frame\", resized_frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code with semantic segmentation\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sam_checkpoint = \"./sam_vit_b.pth\"  # Make sure this path is correct\n",
    "model_type = \"vit_b\"  # Use \"vit_b\" for the small version\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "def detect_circles(image):\n",
    "    \"\"\"Detect circular objects in the frame using HoughCircles\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30, param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        return circles[0, :]  # Return the detected circles\n",
    "    return None\n",
    "\n",
    "def apply_colored_mask(image, mask, color):\n",
    "    \"\"\"Apply color to a binary mask and overlay it on the image.\"\"\"\n",
    "    colored_mask = np.zeros_like(image)  # Create an empty mask the same size as the image\n",
    "    colored_mask[mask == 255] = color  # Apply the color where the mask is active\n",
    "    return cv2.addWeighted(image, 1, colored_mask, 0.6, 0)  # Blend original image with the mask\n",
    "\n",
    "# Load the input image from a file\n",
    "image_path = \"path_to_your_image.jpg\"  # Replace with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "    exit()\n",
    "\n",
    "# Resize the image for faster processing\n",
    "resized_image = cv2.resize(image, (640, 480))\n",
    "resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect circles in the image\n",
    "circles = detect_circles(resized_image)\n",
    "\n",
    "if circles is not None:\n",
    "    for circle in circles:\n",
    "        x, y, r = circle\n",
    "        # Create a mask for the detected circle\n",
    "        mask = np.zeros_like(resized_image[:, :, 0])  # Create a black mask\n",
    "        cv2.circle(mask, (x, y), r, 255, thickness=-1)  # Fill the circle region with white (255)\n",
    "\n",
    "        # Use SAM to predict the mask for the circular region only\n",
    "        predictor.set_image(resized_image_rgb)\n",
    "        masks, scores, logits = predictor.predict(point_coords=None, point_labels=None, multimask_output=True)\n",
    "\n",
    "        # Loop over the masks (choose the highest score mask for simplicity)\n",
    "        best_mask_index = np.argmax(scores)\n",
    "        best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "        # Combine circle mask and segmentation mask (apply segmentation only to the circular area)\n",
    "        combined_mask = cv2.bitwise_and(best_mask, mask)\n",
    "\n",
    "        # Generate a random color for the mask\n",
    "        color = np.random.randint(0, 255, size=(3,), dtype=int).tolist()  # Random BGR color\n",
    "\n",
    "        # Apply the colored mask to the image\n",
    "        colored_image = apply_colored_mask(resized_image, combined_mask, color)\n",
    "\n",
    "        # Draw the detected circle (optional for visualization)\n",
    "        cv2.circle(resized_image, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the results\n",
    "        cv2.imshow(\"Colored Segmentation Mask\", colored_image)\n",
    "else:\n",
    "    cv2.imshow(\"Original Image\", resized_image)\n",
    "\n",
    "# Press any key to close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limport cv2\n",
    "import time\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "# Load the SAM model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"path/to/checkpoint.pth\")\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)  # Change '0' if you have multiple cameras\n",
    "\n",
    "# Capture an image every 3 seconds and perform segmentation\n",
    "while True:\n",
    "    # Capture an image from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image.\")\n",
    "        break\n",
    "\n",
    "    # Set the image for segmentation\n",
    "    predictor.set_image(frame)\n",
    "    \n",
    "    # You can provide manual points for segmentation, or let the model handle it based on other criteria\n",
    "    # Example point (x, y) can be provided based on prior knowledge of chip locations\n",
    "    masks, scores, _ = predictor.predict(point_coords=[[x, y]], point_labels=[1])\n",
    "\n",
    "    # Display the image with segmentation results (optional)\n",
    "    binary_mask = (masks[0] > 0).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw contours on the frame\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "        if 0.7 <= circularity <= 1.2:  # Circularity close to 1 indicates a circle\n",
    "            cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Show the processed image\n",
    "    cv2.imshow('Segmented Image', frame)\n",
    "\n",
    "    # Wait for 3 seconds before capturing the next frame\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyniryo2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries for both camera streaming and segmentation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyniryo2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# For controlling Niryo robot and accessing camera\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyniryo\u001b[39;00m  \u001b[38;5;66;03m# Additional functionalities from pyniryo2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m  \u001b[38;5;66;03m# For image display and manipulation\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyniryo2'"
     ]
    }
   ],
   "source": [
    "#  LATEST SEGMENTATION CODE\n",
    "# Import required libraries for both camera streaming and segmentation\n",
    "from pyniryo2 import *  # For controlling Niryo robot and accessing camera\n",
    "import pyniryo  # Additional functionalities from pyniryo2\n",
    "import cv2 as cv  # For image display and manipulation\n",
    "import torch  # For running the SAM model on GPU/CPU\n",
    "import numpy as np  # For handling arrays and masks\n",
    "from segment_anything import SamPredictor, sam_model_registry  # SAM model utilities for segmentation\n",
    "import time  # For timing and frame rate adjustments\n",
    "\n",
    "# Set up the ROS instance for the Niryo robot, assuming the IP address is \"10.10.10.10\"\n",
    "ros_instance = NiryoRos(\"10.10.10.10\")\n",
    "\n",
    "# Initialize the vision system for the Niryo robot's camera\n",
    "vision = Vision(ros_instance)\n",
    "\n",
    "# Initialize the SAM model (using the small version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, otherwise use CPU\n",
    "sam_checkpoint = \"sam_vit_b_01ec64.pth\"  # Path to the pre-trained SAM model checkpoint (small version)\n",
    "model_type = \"vit_b\"  # Using the small version of the SAM model (vit_b)\n",
    "\n",
    "# Load the SAM model using the specified checkpoint and model type\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device)  # Move the SAM model to the specified device (GPU/CPU)\n",
    "predictor = SamPredictor(sam)  # Initialize the SAM predictor object\n",
    "\n",
    "# Define a function to detect circular objects using color thresholding\n",
    "def detect_circles_by_color(image):\n",
    "    \"\"\"Detect circular objects using color thresholding and contour analysis.\"\"\"\n",
    "    # Convert the image to HSV color space for better color segmentation\n",
    "    hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the color range for detecting circles (for example, detecting red circles)\n",
    "    lower_color = np.array([0, 100, 100])  # Lower bound of the color (e.g., red)\n",
    "    upper_color = np.array([10, 255, 255])  # Upper bound of the color (e.g., red)\n",
    "\n",
    "    # Create a binary mask based on the defined color range\n",
    "    mask = cv.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Use morphological operations to reduce noise\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel)  # Close small holes\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel)   # Remove small noise\n",
    "\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    circles = []\n",
    "    for contour in contours:\n",
    "        # Approximate the contour and check if it is circular\n",
    "        perimeter = cv.arcLength(contour, True)\n",
    "        approx = cv.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "\n",
    "        if len(approx) >= 5:  # If the shape has enough vertices, consider it a circle\n",
    "            (x, y), radius = cv.minEnclosingCircle(contour)\n",
    "            circles.append((int(x), int(y), int(radius)))\n",
    "\n",
    "    return circles\n",
    "\n",
    "# Start the main loop to stream the Niryo camera and apply SAM segmentation\n",
    "while True:\n",
    "    # Step 1: Fetch the compressed image from the Niryo camera\n",
    "    img_compressed = vision.get_img_compressed()\n",
    "\n",
    "    # Step 2: Get the camera calibration details (intrinsics and distortion coefficients)\n",
    "    camera_info = vision.get_camera_intrinsics()\n",
    "\n",
    "    # Step 3: Uncompress the image to get it ready for processing\n",
    "    img_uncompressed = pyniryo.uncompress_image(img_compressed)\n",
    "\n",
    "    # Step 4: Correct the image for camera distortion using the intrinsics and distortion coefficients\n",
    "    img = pyniryo.undistort_image(img_uncompressed, camera_info.intrinsics, camera_info.distortion)\n",
    "\n",
    "    # Step 5: Resize the frame for processing (optional)\n",
    "    resized_frame = cv.resize(img, (640, 480))\n",
    "\n",
    "    # Step 6: Detect circles in the resized frame using color thresholding\n",
    "    circles = detect_circles_by_color(resized_frame)\n",
    "\n",
    "    # Step 7: Prepare to store masks for segmented circles\n",
    "    if circles:\n",
    "        for circle in circles:\n",
    "            x, y, r = circle  # Get the circle's center (x, y) and radius (r)\n",
    "\n",
    "            # Create a mask for the detected circle\n",
    "            circle_mask = np.zeros((resized_frame.shape[0], resized_frame.shape[1]), dtype=np.uint8)  # Create a black mask\n",
    "            cv.circle(circle_mask, (x, y), r, 255, thickness=-1)  # Fill the circle region with white (255)\n",
    "\n",
    "            # Convert the resized frame to RGB format for SAM\n",
    "            resized_frame_rgb = cv.cvtColor(resized_frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "            # Set the image for segmentation using SAM\n",
    "            predictor.set_image(resized_frame_rgb)\n",
    "\n",
    "            # Perform semantic segmentation on the entire frame\n",
    "            masks, scores, _ = predictor.predict(point_coords=None, point_labels=None)\n",
    "\n",
    "            # Use the best mask (highest score)\n",
    "            best_mask_index = np.argmax(scores)\n",
    "            best_mask = masks[best_mask_index].astype(np.uint8) * 255  # Convert the SAM mask to a binary mask (0 or 255)\n",
    "\n",
    "            # Combine the circle mask and the segmentation mask\n",
    "            combined_mask = cv.bitwise_and(best_mask, circle_mask)\n",
    "\n",
    "            # Draw the contours of the combined mask on the original image\n",
    "            contours, _ = cv.findContours(combined_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "            for contour in contours:\n",
    "                cv.drawContours(resized_frame, [contour], -1, (0, 255, 0), 2)  # Draw contours in green\n",
    "\n",
    "    # Display the results\n",
    "    cv.imshow(\"Segmented Circles\", resized_frame)\n",
    "\n",
    "    # Press 'q' to quit the loop\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup resources\n",
    "cv.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
