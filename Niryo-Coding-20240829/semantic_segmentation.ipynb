{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kashi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# completed segmentation\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from pyniryo2 import *  # For controlling the Niryo robot and accessing the camera\n",
    "import pyniryo  # Additional functionalities from pyniryo2\n",
    "\n",
    "# Load the SAM model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "sam.to(device)\n",
    "\n",
    "# Create predictor\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Set up the ROS instance for the Niryo robot\n",
    "ros_instance = NiryoRos(\"169.254.200.200\") # Replace with your Niryo robot's IP address\n",
    "vision = Vision(ros_instance)  # Initialize the vision system\n",
    "\n",
    "# Function to capture and preprocess the image from the Niryo camera\n",
    "def capture_image():\n",
    "    # Fetch the compressed image from the Niryo camera\n",
    "    img_compressed = vision.get_img_compressed()\n",
    "\n",
    "    # Get the camera calibration details (intrinsics and distortion coefficients)\n",
    "    camera_info = vision.get_camera_intrinsics()\n",
    "\n",
    "    # Uncompress the image to get it ready for processing\n",
    "    img_uncompressed = pyniryo.uncompress_image(img_compressed)\n",
    "\n",
    "    # Correct the image for camera distortion using the intrinsics and distortion coefficients\n",
    "    img = pyniryo.undistort_image(img_uncompressed, camera_info.intrinsics, camera_info.distortion)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Capture and prepare the image\n",
    "image = capture_image()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Set the image for segmentation\n",
    "predictor.set_image(image)\n",
    "\n",
    "# Define the input points as a dictionary\n",
    "input_points_dict = {\n",
    "    \"p1\": (50, 50),\n",
    "    \"p5\": (150, 150),\n",
    "}\n",
    "\n",
    "# Convert the dictionary values to a NumPy array\n",
    "input_points = np.array(list(input_points_dict.values()))\n",
    "\n",
    "# Define corresponding labels for each point (assuming all are positive samples)\n",
    "input_labels = np.array([1] * len(input_points))  # All points are positive\n",
    "\n",
    "# Perform segmentation with the first mask output\n",
    "masks, scores, logits = predictor.predict(input_points, input_labels, multimask_output=False)\n",
    "\n",
    "\n",
    "# Create a color mask with the same dimensions as the original image\n",
    "color_mask = np.zeros_like(image)\n",
    "\n",
    "# Define colors for the masks (for example, blue and green)\n",
    "colors = [\n",
    "    (0, 255, 0),  # Green for chip 1\n",
    "    (255, 0, 0),  # Blue for chip 2\n",
    "    (0, 0, 255),  # Red for chip 3\n",
    "    # You can define more colors if you have more chips\n",
    "]\n",
    "\n",
    "# If masks are generated, apply colors\n",
    "if len(masks) > 0:\n",
    "    for i, mask in enumerate(masks):\n",
    "        color = colors[i % len(colors)]  # Cycle through the defined colors\n",
    "        color_mask[mask.astype(bool)] = color  # Assign color to the mask area\n",
    "\n",
    "# Overlay the color mask on the original image\n",
    "overlayed_image = cv2.addWeighted(image, 0.5, color_mask, 0.5, 0)\n",
    "\n",
    "# Save the colored mask and overlayed image\n",
    "cv2.imwrite('colored_mask.png', color_mask)  # Save the colored mask\n",
    "cv2.imwrite('overlayed_image.png', overlayed_image)  # Save the overlayed image\n",
    "\n",
    "# Optionally display the images\n",
    "cv2.imshow('Colored Mask', color_mask)\n",
    "cv2.imshow('Overlayed Image', overlayed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
